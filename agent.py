import json
import base64
import time
import io
import subprocess
import sys
import ctypes
import os
from pathlib import Path
from typing import Optional, Dict, Any, List
from dataclasses import dataclass

import mss
import mss.tools
import pyautogui
import pyperclip
from PIL import Image
from openai import OpenAI

system_prompt = """ä½ æ˜¯ä¸€ä¸ªç”µè„‘æ“ä½œåŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç”¨æˆ·çš„æŒ‡ä»¤ï¼Œé€šè¿‡ä¸€ç³»åˆ—æ“ä½œæ¥å®Œæˆç”¨æˆ·çš„ä»»åŠ¡ã€‚

æ¯æ¬¡å“åº”å¿…é¡»è¿”å›ä¸€ä¸ª JSON å¯¹è±¡ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{
    "thought": "ä½ çš„æ€è€ƒè¿‡ç¨‹ï¼Œåˆ†æå½“å‰å±å¹•çŠ¶æ€å’Œä¸‹ä¸€æ­¥è¯¥åšä»€ä¹ˆ",
    "action": "åŠ¨ä½œç±»å‹",
    "parameters": {
        "å‚æ•° 1": "å€¼ 1",
        "å‚æ•° 2": "å€¼ 2"
    }
}

å¯ç”¨çš„åŠ¨ä½œç±»å‹ï¼š
- click: ç‚¹å‡»ï¼Œå‚æ•°ï¼šx, y (0-1000 çš„å½’ä¸€åŒ–åæ ‡)
- double_click: åŒå‡»ï¼Œå‚æ•°ï¼šx, y
- right_click: å³é”®ç‚¹å‡»ï¼Œå‚æ•°ï¼šx, y
- type: è¾“å…¥æ–‡æœ¬ï¼Œå‚æ•°ï¼štext (è¦è¾“å…¥çš„æ–‡æœ¬)
- press: æŒ‰é”®ï¼Œå‚æ•°ï¼škeys (æŒ‰é”®æ•°ç»„ï¼Œå¦‚ ["ctrl", "c"])
- scroll: æ»šåŠ¨ï¼Œå‚æ•°ï¼šamount (æ»šåŠ¨é‡), x, y (å¯é€‰ï¼Œæ»šåŠ¨ä½ç½®)
- drag: æ‹–æ‹½ï¼Œå‚æ•°ï¼šstart_x, start_y, end_x, end_y, duration (å¯é€‰)
- move: ç§»åŠ¨é¼ æ ‡ï¼Œå‚æ•°ï¼šx, y, duration (å¯é€‰)
- wait: ç­‰å¾…ï¼Œå‚æ•°ï¼šseconds
- run_command: è¿è¡Œç»ˆç«¯å‘½ä»¤ï¼Œå‚æ•°ï¼šcommand (å‘½ä»¤å­—ç¬¦ä¸²), shell (å¯é€‰ï¼Œé»˜è®¤ true), timeout (å¯é€‰ï¼Œè¶…æ—¶ç§’æ•°ï¼Œé»˜è®¤ 30)
- task_complete: ä»»åŠ¡å®Œæˆï¼Œå‚æ•°ï¼šresult (ä»»åŠ¡ç»“æœæè¿°), summary (å¯é€‰ï¼Œä»»åŠ¡æ€»ç»“ï¼ŒåŒ…æ‹¬æ‰§è¡Œæ­¥éª¤å’Œæœ€ç»ˆç­”æ¡ˆ)

æ³¨æ„ï¼š
1. åæ ‡ç³»ç»Ÿä½¿ç”¨ 1000x1000 çš„å½’ä¸€åŒ–åæ ‡ï¼Œ(0,0) æ˜¯å·¦ä¸Šè§’ï¼Œ(1000,1000) æ˜¯å³ä¸‹è§’
2. æ¯æ¬¡åªæ‰§è¡Œä¸€ä¸ªåŠ¨ä½œ
3. ä»”ç»†è§‚å¯Ÿå±å¹•å†…å®¹ï¼Œåšå‡ºåˆç†çš„å†³ç­–
4. å¦‚æœä»»åŠ¡å®Œæˆï¼Œä½¿ç”¨ task_complete åŠ¨ä½œï¼Œå¹¶åœ¨ summary ä¸­æä¾›å®Œæ•´çš„ä»»åŠ¡æ€»ç»“æˆ–ç”¨æˆ·éœ€è¦çš„ç­”æ¡ˆ
5. å¦‚æœé‡åˆ°å›°éš¾ï¼Œå°è¯•ä¸åŒçš„æ–¹æ³•
6. VSCode æ‰“å¼€æ§åˆ¶å°çš„å¿«æ·é”®æ˜¯ ctrl+shift+`
7. window ç”µè„‘ç”¨ Set-Content -Encoding utf8 æ–‡ä»¶å "å†…å®¹" æ¥å†™æ–‡ä»¶
8. task_complete çš„ summary å­—æ®µåº”åŒ…å«ï¼šæ‰§è¡Œçš„ä¸»è¦æ­¥éª¤ã€æœ€ç»ˆç»“æœã€ä»¥åŠç”¨æˆ·éœ€è¦çš„å…·ä½“ç­”æ¡ˆï¼ˆå¦‚æœæœ‰ï¼‰
"""


@dataclass
class Action:
    action_type: str
    parameters: Dict[str, Any]
    thought: str


class ScreenAgent:
    def __init__(self, config_path: str = "config.json"):
        with open(config_path, "r", encoding="utf-8") as f:
            self.config = json.load(f)

        api_config = self.config["api"]
        self.client = OpenAI(
            base_url=api_config["base_url"],
            api_key=api_config["api_key"]
        )
        self.model = api_config["model"]
        self.max_tokens = api_config["max_tokens"]
        self.temperature = api_config["temperature"]

        self.max_iterations = self.config["agent"]["max_iterations"]
        self.delay = self.config["agent"]["delay_between_actions"]
        pyautogui.PAUSE = 0.1
        pyautogui.FAILSAFE = False

        self.screen_width, self.screen_height = pyautogui.size()
        print(f"Screen resolution: {self.screen_width}x{self.screen_height}")
        if self.max_iterations == -1:
            print("Max iterations: unlimited")
        else:
            print(f"Max iterations: {self.max_iterations}")

        self.conversation_history: List[Dict[str, Any]] = []
        self.task_summary: Optional[str] = None
    
    def _check_admin_privilege(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä»¥ç®¡ç†å‘˜æƒé™è¿è¡Œ"""
        try:
            return ctypes.windll.shell32.IsUserAnAdmin() != 0
        except Exception:
            return False

    def capture_screen(self) -> str:
        """æˆªå–å±å¹•å¹¶è¿”å› base64 ç¼–ç çš„å›¾ç‰‡"""
        with mss.mss() as sct:
            monitor = sct.monitors[1]
            screenshot = sct.grab(monitor)

            img = Image.frombytes("RGB", screenshot.size, screenshot.bgra, "raw", "BGRX")

            buffer = io.BytesIO()
            img.save(buffer, format="JPEG", quality=85, optimize=True)
            img_data = buffer.getvalue()

            return base64.b64encode(img_data).decode("utf-8")
    
    def map_coordinates(self, x: float, y: float) -> tuple[int, int]:
        """å°†æ¨¡å‹è¿”å›çš„ 1000x1000 åæ ‡æ˜ å°„åˆ°å®é™…å±å¹•åˆ†è¾¨ç‡"""
        real_x = int(x / 1000 * self.screen_width)
        real_y = int(y / 1000 * self.screen_height)
        return real_x, real_y

    def execute_action(self, action: Action) -> str:
        """æ‰§è¡Œ AI è¿”å›çš„åŠ¨ä½œ"""
        action_type = action.action_type.lower()
        params = action.parameters

        try:
            if action_type == "click":
                x, y = self.map_coordinates(params.get("x", 500), params.get("y", 500))
                x, y = max(0, min(x, self.screen_width - 1)), max(0, min(y, self.screen_height - 1))
                pyautogui.moveTo(x, y, duration=0.3)
                time.sleep(0.1)
                pyautogui.click(button='left')
                time.sleep(0.1)
                return f"Clicked at ({x}, {y})"

            elif action_type == "double_click":
                x, y = self.map_coordinates(params.get("x", 500), params.get("y", 500))
                x, y = max(0, min(x, self.screen_width - 1)), max(0, min(y, self.screen_height - 1))
                pyautogui.moveTo(x, y, duration=0.3)
                time.sleep(0.1)
                pyautogui.doubleClick(button='left')
                time.sleep(0.1)
                return f"Double clicked at ({x}, {y})"

            elif action_type == "right_click":
                x, y = self.map_coordinates(params.get("x", 500), params.get("y", 500))
                x, y = max(0, min(x, self.screen_width - 1)), max(0, min(y, self.screen_height - 1))
                pyautogui.moveTo(x, y, duration=0.3)
                time.sleep(0.1)
                pyautogui.rightClick()
                time.sleep(0.1)
                return f"Right clicked at ({x}, {y})"

            elif action_type == "type":
                text = params.get("text", "")
                old_clipboard = pyperclip.paste()
                try:
                    pyperclip.copy(text)
                    time.sleep(0.1)
                    pyautogui.hotkey("ctrl", "v")
                    time.sleep(0.1)
                finally:
                    pyperclip.copy(old_clipboard)
                return f"Typed: {text}"

            elif action_type == "press":
                keys = params.get("keys", [])
                if isinstance(keys, str):
                    keys = [keys]
                pyautogui.hotkey(*keys)
                return f"Pressed: {'+'.join(keys)}"

            elif action_type == "scroll":
                amount = params.get("amount", 100)
                x = params.get("x")
                y = params.get("y")
                if x is not None and y is not None:
                    x, y = self.map_coordinates(x, y)
                    pyautogui.scroll(amount, x=x, y=y)
                else:
                    pyautogui.scroll(amount)
                return f"Scrolled: {amount}"

            elif action_type == "drag":
                start_x, start_y = self.map_coordinates(params.get("start_x", 500), params.get("start_y", 500))
                end_x, end_y = self.map_coordinates(params.get("end_x", 500), params.get("end_y", 500))
                start_x, start_y = max(0, min(start_x, self.screen_width - 1)), max(0, min(start_y, self.screen_height - 1))
                end_x, end_y = max(0, min(end_x, self.screen_width - 1)), max(0, min(end_y, self.screen_height - 1))
                duration = params.get("duration", 1.0)
                pyautogui.moveTo(start_x, start_y)
                pyautogui.mouseDown()
                pyautogui.moveTo(end_x, end_y, duration=duration)
                pyautogui.mouseUp()
                time.sleep(0.1)
                return f"Dragged from ({start_x}, {start_y}) to ({end_x}, {end_y})"

            elif action_type == "move":
                x, y = self.map_coordinates(params.get("x", 500), params.get("y", 500))
                x, y = max(0, min(x, self.screen_width - 1)), max(0, min(y, self.screen_height - 1))
                duration = params.get("duration", 0.5)
                pyautogui.moveTo(x=x, y=y, duration=duration)
                time.sleep(0.1)
                return f"Moved to ({x}, {y})"

            elif action_type == "wait":
                seconds = params.get("seconds", 1.0)
                time.sleep(seconds)
                return f"Waited for {seconds} seconds"

            elif action_type == "run_command":
                command = params.get("command", "")
                shell = params.get("shell", True)
                timeout = params.get("timeout", 30)
                try:
                    result = subprocess.run(
                        command,
                        shell=shell,
                        capture_output=True,
                        text=True,
                        timeout=timeout,
                        encoding="utf-8",
                        errors="replace"
                    )
                    output = result.stdout.strip()
                    error = result.stderr.strip()
                    return_code = result.returncode
                    response = f"Command: {command}\nReturn code: {return_code}"
                    if output:
                        response += f"\nOutput:\n{output}"
                    if error:
                        response += f"\nError:\n{error}"
                    return response
                except subprocess.TimeoutExpired:
                    return f"Command timed out after {timeout} seconds: {command}"
                except Exception as e:
                    return f"Error executing command: {str(e)}"

            elif action_type == "task_complete":
                result = params.get("result", "Task completed")
                summary = params.get("summary", result)
                self.task_summary = summary
                return f"Result: {result}\nSummary: {summary}"

            else:
                return f"Unknown action type: {action_type}"

        except Exception as e:
            return f"Error executing action: {str(e)}"

    def parse_action(self, response_text: str) -> Optional[Action]:
        """è§£æ AI è¿”å›çš„åŠ¨ä½œ"""
        try:
            import re
            json_match = re.search(r'\{[\s\S]*\}', response_text)
            if json_match:
                action_json = json.loads(json_match.group())
                return Action(
                    action_type=action_json.get("action", "wait"),
                    parameters=action_json.get("parameters", {}),
                    thought=action_json.get("thought", "")
                )
        except Exception as e:
            print(f"Error parsing action: {e}")
        return None

    def run(self, task: str) -> str:
        """è¿è¡Œ Agent å®Œæˆç”¨æˆ·ä»»åŠ¡"""

        self.conversation_history = [
            {"role": "system", "content": system_prompt}
        ]

        print(f"\n{'='*60}")
        print(f"Starting task: {task}")
        print(f"{'='*60}\n")

        iteration = 0
        while self.max_iterations == -1 or iteration < self.max_iterations:
            iteration += 1
            if self.max_iterations != -1:
                print(f"\n--- Iteration {iteration}/{self.max_iterations} ---")
            else:
                print(f"\n--- Iteration {iteration} ---")

            screenshot_base64 = self.capture_screen()
            print("Captured screenshot")

            user_message = {
                "role": "user",
                "content": [
                    {"type": "text", "text": f"å½“å‰ä»»åŠ¡ï¼š{task}\nè¯·åˆ†æå±å¹•å¹¶å†³å®šä¸‹ä¸€æ­¥æ“ä½œã€‚"},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{screenshot_base64}"
                        }
                    }
                ]
            }

            messages = self.conversation_history + [user_message]

            print("Sending to AI...")
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                max_tokens=self.max_tokens,
                temperature=self.temperature
            )

            ai_response = response.choices[0].message.content
            print(f"AI response:\n{ai_response}\n")

            self.conversation_history.append(user_message)
            self.conversation_history.append({
                "role": "assistant",
                "content": ai_response
            })

            action = self.parse_action(ai_response)
            if action is None:
                print("Failed to parse action, retrying...")
                continue

            print(f"Thought: {action.thought}")
            print(f"Executing action: {action.action_type}")

            result = self.execute_action(action)
            print(f"Result: {result}")

            if action.action_type.lower() == "task_complete":
                print(f"\n{'='*60}")
                print("Task completed!")
                print(f"{'='*60}")
                if self.task_summary:
                    print(f"\nğŸ“‹ ä»»åŠ¡æ€»ç»“:\n{self.task_summary}")
                print(f"\n{'='*60}\n")
                return result

            time.sleep(self.delay)

        if self.max_iterations != -1:
            print("\nMax iterations reached without completing the task")
        else:
            print("\nTask interrupted without completing")
        return "Task incomplete - max iterations reached"


def main():
    agent = ScreenAgent()

    task = input("Enter your task: ")
    result = agent.run(task)
    print(f"\nFinal result: {result}")


if __name__ == "__main__":
    main()
